[{"path":"http://justanesta.com/econanalyzr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 econanalyzr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"http://justanesta.com/econanalyzr/articles/calc-change-over-time.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Change Over Time","text":"vignette demonstrates compute change time two core functions: percent_change(start_value, end_value): computes simple relative change. annualize_change(start_values, end_values, time_elapsed, time_unit, year_length = 365.2425): converts growth period annualized rate. small monthly time series illustrate computations:","code":"library(econanalyzr) library(tibble) library(dplyr) set.seed(42)  df <- tibble::tibble(   date  = seq(as.Date(\"2025-01-01\"), by = \"month\", length.out = 12),   value = round(100 * cumprod(1 + rnorm(12, mean = 0.01, sd = 0.01)), 2) )  df #> # A tibble: 12 × 2 #>    date       value #>    <date>     <dbl> #>  1 2025-01-01  102. #>  2 2025-02-01  103. #>  3 2025-03-01  104. #>  4 2025-04-01  106. #>  5 2025-05-01  107. #>  6 2025-06-01  108. #>  7 2025-07-01  111. #>  8 2025-08-01  112. #>  9 2025-09-01  115. #> 10 2025-10-01  117. #> # ℹ 2 more rows"},{"path":"http://justanesta.com/econanalyzr/articles/calc-change-over-time.html","id":"percent-change","dir":"Articles","previous_headings":"","what":"Percent Change","title":"Change Over Time","text":"percent_change() expects starting ending values. natural workflow using [dplyr::lag()] use different values vector vectorized manner:","code":"df_pct <- df |>    arrange(date) |>    mutate(     # vectorized, preserves NA on first row     pct_mom = percent_change(lag(value), value)   ) #> Warning: There was 1 warning in `mutate()`. #> ℹ In argument: `pct_mom = percent_change(lag(value), value)`. #> Caused by warning: #> ! NA values detected; returning NA for those positions.  df_pct |> select(date, value, pct_mom) #> # A tibble: 12 × 3 #>    date       value  pct_mom #>    <date>     <dbl>    <dbl> #>  1 2025-01-01  102. NA       #>  2 2025-02-01  103.  0.00440 #>  3 2025-03-01  104.  0.0136  #>  4 2025-04-01  106.  0.0163  #>  5 2025-05-01  107.  0.0141  #>  6 2025-06-01  108.  0.00894 #>  7 2025-07-01  111.  0.0251  #>  8 2025-08-01  112.  0.00900 #>  9 2025-09-01  115.  0.0302  #> 10 2025-10-01  117.  0.00935 #> # ℹ 2 more rows"},{"path":"http://justanesta.com/econanalyzr/articles/calc-change-over-time.html","id":"annualized-change","dir":"Articles","previous_headings":"","what":"Annualized Change","title":"Change Over Time","text":"annualize_change() function versatile enough able calculate annualized change differing time units (e.g. monthly, weekly, daily) well periods units. also plays nicely [dplyr::lag()]:","code":""},{"path":"http://justanesta.com/econanalyzr/articles/calc-change-over-time.html","id":"annualized-rates-from-1-month-and-3-month-intervals-","dir":"Articles","previous_headings":"Annualized Change","what":"Annualized rates from 1-month and 3-month intervals.","title":"Change Over Time","text":"","code":"df_ann <- df |>    arrange(date) |>    mutate(     ann_1m = annualize_change(       lag(value),        value,        time_elapsed = 1,        time_unit = \"monthly\"       ),     ann_3m = annualize_change(       lag(value, 3),        value,        time_elapsed = 3,        time_unit = \"monthly\"       )   )  df_ann |> select(date, value, ann_1m, ann_3m) #> # A tibble: 12 × 4 #>    date       value  ann_1m ann_3m #>    <date>     <dbl>   <dbl>  <dbl> #>  1 2025-01-01  102. NA      NA     #>  2 2025-02-01  103.  0.0540 NA     #>  3 2025-03-01  104.  0.176  NA     #>  4 2025-04-01  106.  0.214   0.146 #>  5 2025-05-01  107.  0.182   0.191 #>  6 2025-06-01  108.  0.113   0.169 #>  7 2025-07-01  111.  0.346   0.210 #>  8 2025-08-01  112.  0.114   0.186 #>  9 2025-09-01  115.  0.430   0.289 #> 10 2025-10-01  117.  0.118   0.212 #> # ℹ 2 more rows"},{"path":"http://justanesta.com/econanalyzr/articles/econanalyzr-verb-workflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Functions for working with {econanalyzr} tibbles","text":"vignette walks typical econanalyzr workflow: * Build valid econanalyzr tibble required schema. * Compute one-summaries econ_value_summary(). * Append trailing moving average econ_calc_trail_avg(). * Filter closed date interval econ_filter_dates(). * Save table CSV descriptive filename via econ_csv_write_out().","code":"library(econanalyzr) library(dplyr) library(tibble)"},{"path":"http://justanesta.com/econanalyzr/articles/econanalyzr-verb-workflow.html","id":"construct-a-valid-econanalyzr-tibble","dir":"Articles","previous_headings":"","what":"Construct a valid {econanalyzr} tibble","title":"Functions for working with {econanalyzr} tibbles","text":"econanalyzr tables 9 required columns specific order final column viz_type_text. create data two geographic entities (US, CA), ensuring doubles/characters expected.","code":"set.seed(123)  # Monthly dates for a year dates <- seq.Date(as.Date(\"2024-01-01\"), by = \"month\", length.out = 12) geos  <- c(\"US\", \"CA\")  # Cross-join dates and geos, then create values with simple trends by group df0 <- tibble::tibble(   date             = rep(dates, each = length(geos)),   geo_entity_text  = rep(geos,  times = length(dates)) )  |>    arrange(date, geo_entity_text) |>   group_by(geo_entity_text) |>   mutate(     t_seq = row_number(),     value = as.double(if_else(       geo_entity_text == \"US\",       100 + 0.20 * t_seq,   # gentle uptrend for US       98  + 0.15 * t_seq    # gentle uptrend for CA     ))   ) |>   ungroup() |>   mutate(     date_period_text     = \"Monthly\",     data_element_text    = \"Quits Rate\",     data_measure_text    = \"Percent\",     date_measure_text    = \"Monthly\",     data_transform_text  = \"Seasonally Adjusted\",     geo_entity_type_text = \"Nation\",     viz_type_text        = \"Line\"   ) |>   # Put columns in the required order:    # first 9 required, then viz_type_text last   select(     date, date_period_text, value, data_element_text,     data_measure_text, date_measure_text, data_transform_text,     geo_entity_type_text, geo_entity_text, viz_type_text   )  # Validate & normalize (reorders/coerces if needed) df <- econanalyzr:::check_econanalyzr_df(df0)  # Peek at the result df #> # A tibble: 24 × 10 #>    date       date_period_text value data_element_text data_measure_text #>    <date>     <chr>            <dbl> <chr>             <chr>             #>  1 2024-01-01 Monthly           98.2 Quits Rate        Percent           #>  2 2024-01-01 Monthly          100.  Quits Rate        Percent           #>  3 2024-02-01 Monthly           98.3 Quits Rate        Percent           #>  4 2024-02-01 Monthly          100.  Quits Rate        Percent           #>  5 2024-03-01 Monthly           98.4 Quits Rate        Percent           #>  6 2024-03-01 Monthly          101.  Quits Rate        Percent           #>  7 2024-04-01 Monthly           98.6 Quits Rate        Percent           #>  8 2024-04-01 Monthly          101.  Quits Rate        Percent           #>  9 2024-05-01 Monthly           98.8 Quits Rate        Percent           #> 10 2024-05-01 Monthly          101   Quits Rate        Percent           #> # ℹ 14 more rows #> # ℹ 5 more variables: date_measure_text <chr>, data_transform_text <chr>, #> #   geo_entity_type_text <chr>, geo_entity_text <chr>, viz_type_text <chr>"},{"path":"http://justanesta.com/econanalyzr/articles/econanalyzr-verb-workflow.html","id":"one-off-summaries-with-econ_value_summary","dir":"Articles","previous_headings":"","what":"One off summaries with econ_value_summary()","title":"Functions for working with {econanalyzr} tibbles","text":"can compute statistic numeric column applying either date membership filter (dates) closed range (date_range).","code":"# Mean of 'value' for the last 3 months of US only df_us   <- filter(df, geo_entity_text == \"US\") last_3  <- tail(unique(df_us$date), 3) mean_us_last3 <- econ_value_summary(   df       = df_us,   dates    = last_3,   .fun     = mean,   na_rm    = TRUE ) mean_us_last3 #> [1] 102.2  # Median over an *exclusive* range (drop rows in range) for CA df_ca   <- filter(df, geo_entity_text == \"CA\") rng     <- as.Date(c(\"2024-04-01\",\"2024-08-01\")) med_ca_exclusive <- econ_value_summary(   df          = df_ca,   date_range  = rng,   filter_type = \"exclusive\",   .fun        = median ) med_ca_exclusive #> [1] 99.35  # Vector summary (quantiles) over all rows q_all <- econ_value_summary(   df    = df_us,   .fun  = function(x) stats::quantile(x, probs = c(.25, .5, .75), names = TRUE) ) q_all #>    25%    50%    75%  #> 100.75 101.30 101.85"},{"path":"http://justanesta.com/econanalyzr/articles/econanalyzr-verb-workflow.html","id":"append-a-trailing-moving-average-in-long-form","dir":"Articles","previous_headings":"","what":"Append a trailing moving average in long form","title":"Functions for working with {econanalyzr} tibbles","text":"econ_calc_trail_avg() computes right-aligned trailing window appends derived rows original table long form. input grouped, trailing average computed within groups.","code":"# Group by geo and compute a 3-period trailing average per series df_trailing <- df |>    group_by(geo_entity_text) |>    econ_calc_trail_avg(trail_amount = 3L)  # The result contains original rows + trailing-average rows (twice the number of rows here) nrow(df) #> [1] 24 nrow(df_trailing) #> [1] 48  # Show the df_trailing data frame df_trailing |>    filter(grepl(\"Trail\", data_transform_text)) #> # A tibble: 24 × 10 #>    date       date_period_text value data_element_text data_measure_text #>    <date>     <chr>            <dbl> <chr>             <chr>             #>  1 2024-01-01 Monthly           NA   Quits Rate        Percent           #>  2 2024-02-01 Monthly           NA   Quits Rate        Percent           #>  3 2024-03-01 Monthly           98.3 Quits Rate        Percent           #>  4 2024-04-01 Monthly           98.4 Quits Rate        Percent           #>  5 2024-05-01 Monthly           98.6 Quits Rate        Percent           #>  6 2024-06-01 Monthly           98.8 Quits Rate        Percent           #>  7 2024-07-01 Monthly           98.9 Quits Rate        Percent           #>  8 2024-08-01 Monthly           99.0 Quits Rate        Percent           #>  9 2024-09-01 Monthly           99.2 Quits Rate        Percent           #> 10 2024-10-01 Monthly           99.4 Quits Rate        Percent           #> # ℹ 14 more rows #> # ℹ 5 more variables: date_measure_text <chr>, data_transform_text <chr>, #> #   geo_entity_type_text <chr>, geo_entity_text <chr>, viz_type_text <chr>"},{"path":"http://justanesta.com/econanalyzr/articles/econanalyzr-verb-workflow.html","id":"filter-by-a-closed-date-interval","dir":"Articles","previous_headings":"","what":"Filter by a closed date interval","title":"Functions for working with {econanalyzr} tibbles","text":"Use econ_filter_dates() filter explicit interval, derive start date period (days/weeks/months/quarters/years). econanalyzr tibbles always YYYY-MM-DD format earlier date period. date Q2 2025 2025-04-01 2026 year 2026-01-01.","code":"# A) Explicit interval (closed): filtered_closed <- econ_filter_dates(   df,   start_date = as.Date(\"2024-06-01\"),   end_date   = as.Date(\"2024-10-01\") ) #> Filtered to [2024-06-01, 2024-10-01] (closed interval). filtered_closed #> # A tibble: 10 × 10 #>    date       date_period_text value data_element_text data_measure_text #>    <date>     <chr>            <dbl> <chr>             <chr>             #>  1 2024-10-01 Monthly           99.5 Quits Rate        Percent           #>  2 2024-10-01 Monthly          102   Quits Rate        Percent           #>  3 2024-09-01 Monthly           99.4 Quits Rate        Percent           #>  4 2024-09-01 Monthly          102.  Quits Rate        Percent           #>  5 2024-08-01 Monthly           99.2 Quits Rate        Percent           #>  6 2024-08-01 Monthly          102.  Quits Rate        Percent           #>  7 2024-07-01 Monthly           99.0 Quits Rate        Percent           #>  8 2024-07-01 Monthly          101.  Quits Rate        Percent           #>  9 2024-06-01 Monthly           98.9 Quits Rate        Percent           #> 10 2024-06-01 Monthly          101.  Quits Rate        Percent           #> # ℹ 5 more variables: date_measure_text <chr>, data_transform_text <chr>, #> #   geo_entity_type_text <chr>, geo_entity_text <chr>, viz_type_text <chr>  # B) Derived interval: \"last 6 months\" ending at the table’s latest date filtered_open <- econ_filter_dates(   df,   period_type   = \"months\",   period_amount = 6 ) #> Filtered to [2024-06-01, 2024-12-01] (closed interval). filtered_open #> # A tibble: 14 × 10 #>    date       date_period_text value data_element_text data_measure_text #>    <date>     <chr>            <dbl> <chr>             <chr>             #>  1 2024-12-01 Monthly           99.8 Quits Rate        Percent           #>  2 2024-12-01 Monthly          102.  Quits Rate        Percent           #>  3 2024-11-01 Monthly           99.6 Quits Rate        Percent           #>  4 2024-11-01 Monthly          102.  Quits Rate        Percent           #>  5 2024-10-01 Monthly           99.5 Quits Rate        Percent           #>  6 2024-10-01 Monthly          102   Quits Rate        Percent           #>  7 2024-09-01 Monthly           99.4 Quits Rate        Percent           #>  8 2024-09-01 Monthly          102.  Quits Rate        Percent           #>  9 2024-08-01 Monthly           99.2 Quits Rate        Percent           #> 10 2024-08-01 Monthly          102.  Quits Rate        Percent           #> # ℹ 4 more rows #> # ℹ 5 more variables: date_measure_text <chr>, data_transform_text <chr>, #> #   geo_entity_type_text <chr>, geo_entity_text <chr>, viz_type_text <chr>"},{"path":"http://justanesta.com/econanalyzr/articles/econanalyzr-verb-workflow.html","id":"write-to-a-csv-with-a-descriptive-filename","dir":"Articles","previous_headings":"","what":"Write to a CSV with a descriptive filename","title":"Functions for working with {econanalyzr} tibbles","text":"","code":"out_dir <- tempdir() csv_path <- econ_csv_write_out(   df = filtered_open,   folder = out_dir,   overwrite = TRUE,     quiet = FALSE       )"},{"path":"http://justanesta.com/econanalyzr/articles/get-bls.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Retrieving Data From BLS Text File Database","text":"vignette describes use get_bls_data() function. wrapper around [httr2::request()] httr2 package also prompts supply valid email address user-agent HTTPS header now required BLS per terms use.","code":"library(econanalyzr)"},{"path":"http://justanesta.com/econanalyzr/articles/get-bls.html","id":"retrieving-data","dir":"Articles","previous_headings":"","what":"Retrieving data","title":"Retrieving Data From BLS Text File Database","text":"valid URL BLS flat/text file database must supplied well valid email retrieve data. example uses data BLS Current Employment Statistics","code":"valid_email <- \"you@example.com\" # Link to employment data for the Government sector bls_url <- \"https://download.bls.gov/pub/time.series/ce/ce.data.90a.Government.Employment\"   df <- get_bls_data(   bls_url = bls_url,   email = valid_email )"},{"path":"http://justanesta.com/econanalyzr/articles/working-with-indexes.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Calculating Indices","text":"vignette shows two common transformations economic time series survey-style data: * create_index(): turn numeric vector either base-100 index (base value = 100) base-0 index (mirrors percent change) (base value = 0). * base can selected position name vector named. * create_diffusion_index(): compute diffusion index survey-style proportions respondents increasing, decreasing, unchanged. methods function can execute : * Federal Reserve: (pct_increased - pct_decreased) * 100 * IHS-PMI: (pct_increased + 0.5 * pct_unchanged) * 100 * Conference Board: encode unit’s pct_change 1 / 0.5 / 0 based threshold .0005, calculate average multiply 100.","code":"library(econanalyzr) library(dplyr) library(tibble)"},{"path":"http://justanesta.com/econanalyzr/articles/working-with-indexes.html","id":"indexing-with-create_index","dir":"Articles","previous_headings":"","what":"Indexing with create_index()","title":"Calculating Indices","text":"Basic usage numeric vector Selecting base position name Vectorization works within groups can used inside [dplyr::mutate()] calculate indices.","code":"x <- c(10, 34, 46, 74, 83, 110, 129)  # Base-100 index (default is to have base be the first element) idx_100 <- create_index(x)  # Base-0 (this is effectively calculating the percentage change from base and multiplying by 100) idx_pct <- create_index(x, idx_type = 0)  idx_100 #> [1]  100  340  460  740  830 1100 1290 idx_pct #> [1]    0  240  360  640  730 1000 1190 # By position: use the second element as the base idx_pos2 <- create_index(x, idx_pos = 2)  # By name: works only if the vector is named x_named <- c(a = 10, b = 34, c = 46, d = 74, e = 83, f = 110, g = 129) idx_name_b_100 <- create_index(x_named, idx_pos = \"b\")          # base-100 idx_name_b_pct <- create_index(x_named, idx_pos = \"b\", idx_type = 0)  # % from \"b\"  idx_pos2 #> [1]  29.41176 100.00000 135.29412 217.64706 244.11765 323.52941 379.41176 idx_name_b_100 #>         a         b         c         d         e         f         g  #>  29.41176 100.00000 135.29412 217.64706 244.11765 323.52941 379.41176 idx_name_b_pct #>         a         b         c         d         e         f         g  #> -70.58824   0.00000  35.29412 117.64706 144.11765 223.52941 279.41176 df_state <- tibble::tibble(   series = rep(c(\"US\", \"CA\"), each = 5),   value  = c(80, 82, 85, 84, 90,   100, 98,  99, 101, 105) )  # Base-100 per series (base = first value within each group) df_idx <- df_state %>%   group_by(series) %>%   mutate(index_100 = create_index(value)) %>%   ungroup()  df_idx #> # A tibble: 10 × 3 #>    series value index_100 #>    <chr>  <dbl>     <dbl> #>  1 US        80      100  #>  2 US        82      102. #>  3 US        85      106. #>  4 US        84      105  #>  5 US        90      112. #>  6 CA       100      100  #>  7 CA        98       98  #>  8 CA        99       99  #>  9 CA       101      101  #> 10 CA       105      105"},{"path":"http://justanesta.com/econanalyzr/articles/working-with-indexes.html","id":"diffusion-indices-with-create_diffusion_index","dir":"Articles","previous_headings":"","what":"Diffusion indices with create_diffusion_index()","title":"Calculating Indices","text":"Diffusion indices commonly derived survey responses used way gauge breadth amplitude change collection economic variables like employment, manufacturing, business conditions. create_diffusion_index() function provides three common vectorized ways way calculate .","code":""},{"path":"http://justanesta.com/econanalyzr/articles/working-with-indexes.html","id":"federal-reserve-method","dir":"Articles","previous_headings":"Diffusion indices with create_diffusion_index()","what":"Federal Reserve method","title":"Calculating Indices","text":"pct_decreased value simply subtracted pct_increased value multiplied 100. index centered 0 number 0 indicates expansion positive reading number 0 contraction negative reading.","code":"fed <- create_diffusion_index(   pct_increased = c(0.60, 0.55, 0.50),   pct_decreased = c(0.20, 0.25, 0.30),   idx_type      = \"Federal Reserve\" ) fed #> [1] 40 30 20"},{"path":"http://justanesta.com/econanalyzr/articles/working-with-indexes.html","id":"ihs-pmi-method","dir":"Articles","previous_headings":"","what":"IHS-PMI method","title":"Calculating Indices","text":"sum pct_increased value half pct_unchanged value multiplied 100. index centered 50 number 50 indicates expansion positive reading number 50 contraction negative reading. example, diffusion index change 53 59 accelerating growth, change 59 51 decelerating growth, change 51 44 accelerating contraction, change 44 49 decelerating contraction.","code":"ihs <- create_diffusion_index(   pct_increased = c(0.55, 0.45, 0.52),   pct_unchanged = c(0.30, 0.35, 0.28),   idx_type      = \"IHS-PMI\" ) ihs #> [1] 70.0 62.5 66.0"},{"path":"http://justanesta.com/econanalyzr/articles/working-with-indexes.html","id":"conference-board-method","dir":"Articles","previous_headings":"","what":"Conference Board method","title":"Calculating Indices","text":"method encodes pct_change value : * 1 pct_change greater .0005. * 0.5 pct_change -.0005 .0005. * 0 pct_change less -.0005. returns mean encoded values multiplied 100. Since functions vectorized, play nice tidy syntax [tibble::tibble()]:","code":"# Example: a small panel of unit-level percent changes for a month pct_change <- c(0.003, -0.002, 0.0002, 0.0, 0.0011)  conf_board <- create_diffusion_index(   pct_change = pct_change,   idx_type   = \"Conference Board\" ) conf_board #> [1] 60 survey <- tibble::tibble(   month         = as.Date(c(\"2025-01-01\",\"2025-02-01\",\"2025-03-01\")),   pct_inc       = c(0.60, 0.55, 0.52),   pct_dec       = c(0.20, 0.22, 0.25),   pct_unch      = c(0.20, 0.23, 0.23) )  survey |>    transmute(     fed_idx = create_diffusion_index(       pct_inc,        pct_dec,        idx_type = \"Federal Reserve\"       ),     ihs_idx = create_diffusion_index(       pct_increased = pct_inc,        pct_unchanged = pct_unch,        idx_type = \"IHS-PMI\"       )   ) #> # A tibble: 3 × 2 #>   fed_idx ihs_idx #>     <dbl>   <dbl> #> 1      40    70   #> 2      33    66.5 #> 3      27    63.5"},{"path":"http://justanesta.com/econanalyzr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Adrian Nesta. Author, maintainer.","code":""},{"path":"http://justanesta.com/econanalyzr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Nesta (2025). econanalyzr: Helps Analyze Economic Data. R package version 1.0.0, https://anesta95.github.io/econanalyzr/.","code":"@Manual{,   title = {econanalyzr: Helps You Analyze Economic Data},   author = {Adrian Nesta},   year = {2025},   note = {R package version 1.0.0},   url = {https://anesta95.github.io/econanalyzr/}, }"},{"path":"http://justanesta.com/econanalyzr/index.html","id":"econanalyzr","dir":"","previous_headings":"","what":"Helps You Analyze Economic Data","title":"Helps You Analyze Economic Data","text":"goal econanalyzr provide collection functions helper datasets help users obtain, analyze, visualize economic data. functions can broken data import functions, data analysis functions, data visualization functions. commonly used functions currently available: get_bls_data() wrapper sends HTTP requests BLS site valid user-supplied email download TSV data flat file database. percent_change() calculates percentage change two numeric scalars vectors. annualize_change() calculate annualized rate change two numeric scalars vectors given time period. create_index() calculates 0 100-based index version numeric vector based starting value supplied. create_diffusion_index() calculates diffusion index two numeric scalars vectors based Federal Reserve IHS Markit methods one numeric scalar vector based Conference Board method.","code":""},{"path":"http://justanesta.com/econanalyzr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Helps You Analyze Economic Data","text":"can install development version econanalyzr GitHub :","code":"pak::pak(\"anesta95/econanalyzr\") # or devtools::install_github(\"anesta95/econanalyzr\")"},{"path":"http://justanesta.com/econanalyzr/index.html","id":"data-import-examples","dir":"","previous_headings":"","what":"Data Import Examples","title":"Helps You Analyze Economic Data","text":"Use get_bls_data() function get TSV data BLS survey flat file database. function require provide valid email request user-agent now required programmatically obtain BLS data way.","code":"library(econanalyzr) bls_jolts <- get_bls_data(   bls_url = \"https://download.bls.gov/pub/time.series/jt/jt.data.1.AllItems\",    email = \"govdata.decimeter618@passmail.net\"   )  str(bls_jolts) #> spc_tbl_ [607,649 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #>  $ series_id     : chr [1:607649] \"JTS000000000000000HIL\" \"JTS000000000000000HIL\" \"JTS000000000000000HIL\" \"JTS000000000000000HIL\" ... #>  $ year          : chr [1:607649] \"2000\" \"2001\" \"2001\" \"2001\" ... #>  $ period        : chr [1:607649] \"M12\" \"M01\" \"M02\" \"M03\" ... #>  $ value         : chr [1:607649] \"5426\" \"5722\" \"5303\" \"5528\" ... #>  $ footnote_codes: chr [1:607649] NA NA NA NA ... #>  - attr(*, \"spec\")= #>   .. cols( #>   ..   .default = col_character(), #>   ..   series_id = col_character(), #>   ..   year = col_character(), #>   ..   period = col_character(), #>   ..   value = col_character(), #>   ..   footnote_codes = col_character() #>   .. ) #>  - attr(*, \"problems\")=<externalptr>"},{"path":"http://justanesta.com/econanalyzr/index.html","id":"data-analysis-examples","dir":"","previous_headings":"","what":"Data Analysis Examples","title":"Helps You Analyze Economic Data","text":"Use percent_change() function calculate percentage change two numeric scalars vectors: Use annualize_change() function calculate annualized one month change two numeric vectors values: Use create_index() transform vector numeric values 0 100 based index: Use create_diffusion_index() calculate Federal Reserve IHS diffusion index numeric values percent increase, percent unchanged, percent decreasing Conference Board diffusion index percent change values.","code":"library(econanalyzr) # Scalar → scalar percent_change(100, 120) #> [1] 0.2  # Vectorized (pairwise) percent_change(c(100, 80, 50), c(110, 72, 55)) #> [1]  0.1 -0.1  0.1  # Scalar recycling (start is scalar) percent_change(100, c(101, 105, 120)) #> [1] 0.01 0.05 0.20  # NA propagates (emits a classed warning) percent_change(c(100, NA), c(110, 120)) #> Warning: NA values detected; returning NA for those positions. #> [1] 0.1  NA  # Division by zero yields NA (with a single classed warning) percent_change(c(0, 10), c(5, 15)) #> Warning: Division by zero in `start_value`; returning NA for those positions. #> [1]  NA 0.5 library(econanalyzr)  # Monthly: from 100 to 103 over 1 month (12 months/year) annualize_change(100, 103, time_elapsed = 1, time_unit = \"monthly\") #> [1] 0.4257609  # Vectorized, scalar recycling (quarterly): exponent = 4 / time_elapsed annualize_change(   start_values = 100,   end_values   = c(101, 98, 120),   time_elapsed = 2,   time_unit    = \"quarterly\" ) #> [1]  0.0201 -0.0396  0.4400  # Daily with default Gregorian year_length = 365.2425 annualize_change(100, 101, time_elapsed = 10, time_unit = \"daily\") #> [1] 0.4382518  # Weekly using exact 52-week convention (364 days) annualize_change(100, 101, time_elapsed = 2, time_unit = \"weekly\", year_length = 364) #> [1] 0.2952563 library(econanalyzr)  # Base-100 index (default): base is the first element (50 -> 100) create_index(c(50, 100, 150)) #> [1] 100 200 300  # Percent-change index (idx_type = 0): base becomes 0% create_index(c(90, 100, 120), idx_pos = 2, idx_type = 0) #> [1] -10   0  20  # Select base by *name* (only if the vector is named) x <- c(\"2023-01\" = 80, \"2023-02\" = 100, \"2023-03\" = 120) create_index(x, idx_pos = \"2023-02\")            # base-100 with named base #> 2023-01 2023-02 2023-03  #>      80     100     120  create_index(x, idx_pos = \"2023-02\", idx_type = 0)  # percent change from \"2023-02\" #> 2023-01 2023-02 2023-03  #>     -20       0      20  # Non-base NA/NaN/Inf values warn once and propagate y <- c(100, NA, 200) create_index(y, idx_pos = 1) #> Warning: Some non-base values are NA/NaN/Inf; resulting index will contain #> NA/NaN at those positions. #> [1] 100  NA 200 library(econanalyzr)  # Federal Reserve method: (pct_increased − pct_decreased) * 100 create_diffusion_index(   pct_increased = c(0.60, 0.55, 0.40),   pct_decreased = c(0.20, 0.25, 0.35),   idx_type      = \"Federal Reserve\" ) #> [1] 40 30  5  # Scalar recycling with FR (scalar increased, vector decreased) create_diffusion_index(   pct_increased = 0.50,   pct_decreased = c(0.20, 0.25, 0.35),   idx_type      = \"Federal Reserve\" ) #> [1] 30 25 15  # IHS-PMI method: (pct_increased + 0.5 * pct_unchanged) * 100 create_diffusion_index(   pct_increased = c(0.55, 0.50),   pct_unchanged = c(0.30, 0.35),   idx_type      = \"IHS-PMI\" ) #> [1] 70.0 67.5  # Conference Board method (threshold ±0.05%): encode and average pc <- c(+0.0010, +0.0005, 0.0000, -0.0005, -0.0020) create_diffusion_index(pct_change = pc, idx_type = \"Conference Board\") #> [1] 50  # Conference Board with NA: NA are dropped from the mean (warns once) create_diffusion_index(pct_change = c(0.001, NA, -0.001), idx_type = \"Conference Board\") #> Warning: NA values found in `pct_change`; they will be dropped when averaging. #> [1] 50   # All NA example returns NA (single, specific warning) create_diffusion_index(pct_change = c(NA_real_, NA_real_), idx_type = \"Conference Board\") #> Warning: All encoded values are NA; returning NA_real_. #> [1] NA"},{"path":"http://justanesta.com/econanalyzr/index.html","id":"econanalyzr-tibble-structure-and-functions","dir":"","previous_headings":"","what":"econanalyzr Tibble Structure and Functions","title":"Helps You Analyze Economic Data","text":"Every econ analysis data CSV file minimum following columns: date: date associated data data row. date YYYY-MM-DD format regardless time period date captures. dates first day time period. example, data April 2025 displayed 2025-04-01. Data Q2 2025 2025-04-01. Data year 2025 2025-01-01. data type double class Date. date_period_text: time period row data captures. common formats Monthly, Quarterly, Annually. data type class character. value: value measured data. data type double class numeric. data_element_text: data value column describes. data type class character. data_measure_text: mathematical expression data value column expressed . common Level, Rate, Ratio, Percentage, Proportion, Index. data type class character. date_measure_text: change dates measured data value column. common Current, Year--year, Month--month Quarter--quarter. data type class character. data_transform_text: mathematical transformations applied data. common Raw, Percent change, Annualized, Trail N N number periods date_period_text column. can multiple transformations row. Transformations delimited semi-colons ; stated order transformation. example, Trail 3;Percent change percentage change trailing 3 period average current period — denoted date column — trailing 3 period average previous period deduced date_measure_text. Conversely, Percent change;Trail 3 trailing 3 period average applied percentage change current period previous period across data series. data type class character. geo_entity_type_text: geographic entity type data value column covering. data type class character. region United States good chance within Census Bureau Geographic Entity Hierarchy. geo_entity_text: name(s) geographic entity/entities described data. viz_type_text: type visualization made data value column. common Time series line, Bar, Map, Scatter. data type class character.","code":""},{"path":"http://justanesta.com/econanalyzr/index.html","id":"naming-conventions","dir":"","previous_headings":"econanalyzr Tibble Structure and Functions","what":"Naming conventions","title":"Helps You Analyze Economic Data","text":"CSVs PNGs named following format aspect data delimited dash - spaces replaced underscores _. Data visualization files named following order: date date_period_text data_element_text data_measure_text date_measure_text data_transform_text geo_entity_type_text geo_entity_text aspects data specific release needed uniquely identify . Examples include industry_text, size_class_text, seas_adj_text, among others. viz_type_text data file chart names multiple dates date field — files viz_type_text Time series line — date file naming convention least recent dates data series.","code":""},{"path":"http://justanesta.com/econanalyzr/index.html","id":"examples","dir":"","previous_headings":"econanalyzr Tibble Structure and Functions > Naming conventions","what":"Examples","title":"Helps You Analyze Economic Data","text":"2025-04-01_2023-04-01-monthly-quits-rate-current-2_data_transform-nation-us-total_nonfarm-all_size_classes-seasonally_adjusted-time_series_line.csv 2025-04-01-monthly-job_openings-rate-year--year-trail_3_percent_change-nation-us-12_industry-all_size_classes-seasonally_adjusted-bar.csv 2025-04-01_2023-04-01-monthly-quits-rate-current-2_data_transform-nation-us-total_nonfarm-all_size_classes-seasonally_adjusted-time_series_line.png 2025-04-01-monthly-job_openings-rate-year--year-trail_3_percent_change-nation-us-12_industry-all_size_classes-seasonally_adjusted-bar.png Every column dataset _text suffix included filename, addition date column. Data files also include columns information needed uniquely identify data series. Examples include value column, variables _code suffix industry_code, fips_code,preliminary_code, well moe, moe_level, among others.","code":""},{"path":"http://justanesta.com/econanalyzr/index.html","id":"functions","dir":"","previous_headings":"","what":"Functions","title":"Helps You Analyze Economic Data","text":"econ_value_summary() filters econanalyzr-valid data frame either set dates closed date range, pulls numeric column (defaults “value”), applies user-supplied function filtered vector. econ_calc_trail_avg() computes right-aligned trailing average value based user-specified window appends rows econanalyzr tibble long form. Incomplete windows produce NA, ; Trail {n} appended data_transform_text field n length window. econ_filter_dates() filters econanalyzr-valid data frame closed date interval [start_date, end_date]. start_date omitted, can specify period (period_type + period_amount) derives start_date = end_date − period (end_date defaulting latest non-NA date). Returns rows inclusive bounds ordered newest-first. econ_csv_write_out() validates econanalyzr data frame writes CSV using descriptive filename built date span *_text columns.","code":"library(econanalyzr)  # Minimal econanalyzr-valid example data df <- tibble::tibble(   date                 = seq(as.Date(\"2025-01-01\"), by = \"month\", length.out = 6),   date_period_text     = \"Monthly\",   value                = c(100, 105, 103, 108, 112, 115),  # numeric (double)   data_element_text    = \"Quits Rate\",   data_measure_text    = \"Percent\",   date_measure_text    = \"Monthly\",   data_transform_text  = \"SA\",   geo_entity_type_text = \"Nation\",   geo_entity_text      = \"US\",   viz_type_text        = \"Line\" )  # 1) Inclusive set of dates: mean(value) on Feb & May 2025 econanalyzr::econ_value_summary(   df,   dates       = as.Date(c(\"2025-02-01\", \"2025-05-01\")),   filter_type = \"inclusive\",   .fun        = mean,          # any function or function name is fine   na_rm       = TRUE           # drop NAs before calling .fun ) #> [1] 108.5  # 2) Exclusive closed range: median(value) with Jan–Mar 2025 dropped econanalyzr::econ_value_summary(   df,   date_range  = as.Date(c(\"2025-01-01\", \"2025-03-31\")),   filter_type = \"exclusive\",   # drop rows in the range   .fun        = median ) #> [1] 112  # 3) Vector-returning function: quantiles over all dates econanalyzr::econ_value_summary(   df,   .fun = function(x) stats::quantile(x, c(.25, .5, .75))  # returns a numeric vector ) #>   25%   50%   75%  #> 103.5 106.5 111.0 library(econanalyzr)  # Minimal econanalyzr-valid data (one series) df <- tibble::tibble(   date                 = seq(as.Date(\"2025-01-01\"), by = \"month\", length.out = 6),   date_period_text     = \"Monthly\",   value                = c(100, 105, 103, 108, 112, 115),  # double   data_element_text    = \"Quits Rate\",   data_measure_text    = \"Percent\",   date_measure_text    = \"Monthly\",   data_transform_text  = \"SA\",   geo_entity_type_text = \"Nation\",   geo_entity_text      = \"US\",   viz_type_text        = \"Line\" )  # Append a 3-period trailing average (right-aligned; first 2 windows are NA) trail_df <- econanalyzr::econ_calc_trail_avg(df, trail_amount = 3) # Trailing-average rows are appended; identify them by the suffix in data_transform_text dplyr::filter(trail_df, grepl(\"; Trail 3$\", data_transform_text)) |>   dplyr::select(date, value, data_transform_text) #> # A tibble: 6 × 3 #>   date       value data_transform_text #>   <date>     <dbl> <chr>               #> 1 2025-01-01   NA  SA; Trail 3         #> 2 2025-02-01   NA  SA; Trail 3         #> 3 2025-03-01  103. SA; Trail 3         #> 4 2025-04-01  105. SA; Trail 3         #> 5 2025-05-01  108. SA; Trail 3         #> 6 2025-06-01  112. SA; Trail 3  # --- Grouped example: compute trailing average within each series ----------------  df_g <- tibble::tibble(   date                 = rep(seq(as.Date(\"2025-01-01\"), by = \"month\", length.out = 5), each = 2),   date_period_text     = \"Monthly\",   value                = as.double(c(100, 200, 105, 210, 103, 220, 108, 230, 112, 240)),   data_element_text    = \"Quits Rate\",   data_measure_text    = \"Percent\",   date_measure_text    = \"Monthly\",   data_transform_text  = \"SA\",   geo_entity_type_text = \"Nation\",   geo_entity_text      = rep(c(\"US\",\"CA\"), times = 5),   viz_type_text        = \"Line\" )  out_g <- df_g |>   dplyr::group_by(geo_entity_text) |>   econanalyzr::econ_calc_trail_avg(3)  # Show trailing-average rows per country (suffix identifies derived rows) dplyr::filter(out_g, grepl(\"; Trail 3$\", data_transform_text)) |>   dplyr::select(geo_entity_text, date, value, data_transform_text) |>   dplyr::arrange(geo_entity_text, date) #> # A tibble: 10 × 4 #>    geo_entity_text date       value data_transform_text #>    <chr>           <date>     <dbl> <chr>               #>  1 CA              2025-01-01   NA  SA; Trail 3         #>  2 CA              2025-02-01   NA  SA; Trail 3         #>  3 CA              2025-03-01  210  SA; Trail 3         #>  4 CA              2025-04-01  220  SA; Trail 3         #>  5 CA              2025-05-01  230  SA; Trail 3         #>  6 US              2025-01-01   NA  SA; Trail 3         #>  7 US              2025-02-01   NA  SA; Trail 3         #>  8 US              2025-03-01  103. SA; Trail 3         #>  9 US              2025-04-01  105. SA; Trail 3         #> 10 US              2025-05-01  108. SA; Trail 3 #> Each country's trailing means are computed independently within its group. library(econanalyzr)  # Minimal econanalyzr-valid table (10 monthly points) df <- tibble::tibble(   date                 = seq(as.Date(\"2024-09-01\"), by = \"month\", length.out = 10),   date_period_text     = \"Monthly\",   value                = as.double(1:10 * 10),   data_element_text    = \"Quits Rate\",   data_measure_text    = \"Percent\",   date_measure_text    = \"Monthly\",   data_transform_text  = \"SA\",   geo_entity_type_text = \"Nation\",   geo_entity_text      = \"US\",   viz_type_text        = \"Line\" )  # 1) Last 4 months ending at the table’s latest date (derives start_date) last4 <- econanalyzr::econ_filter_dates(   df, period_type = \"months\", period_amount = 4 ) #> Filtered to [2025-02-01, 2025-06-01] (closed interval). dplyr::select(last4, date, value) #> # A tibble: 5 × 2 #>   date       value #>   <date>     <dbl> #> 1 2025-06-01   100 #> 2 2025-05-01    90 #> 3 2025-04-01    80 #> 4 2025-03-01    70 #> 5 2025-02-01    60   # 2) Between explicit dates (inclusive) rng <- econanalyzr::econ_filter_dates(   df,   start_date = as.Date(\"2025-02-01\"),   end_date   = as.Date(\"2025-06-01\") ) #> Filtered to [2025-02-01, 2025-06-01] (closed interval). dplyr::select(rng, date, value) #> # A tibble: 5 × 2 #>   date       value #>   <date>     <dbl> #> 1 2025-06-01   100 #> 2 2025-05-01    90 #> 3 2025-04-01    80 #> 4 2025-03-01    70 #> 5 2025-02-01    60 library(econanalyzr)  # Minimal econanalyzr-valid tibble df <- tibble::tibble(   date                 = seq(as.Date(\"2025-01-01\"), by = \"month\", length.out = 6),   date_period_text     = \"Monthly\",   value                = c(100, 105, 103, 108, 112, 115),   data_element_text    = \"Quits Rate\",   data_measure_text    = \"Percent\",   date_measure_text    = \"Monthly\",   data_transform_text  = \"SA\",   geo_entity_type_text = \"Nation\",   geo_entity_text      = \"US\",   viz_type_text        = \"Line\" )  # Write to a temporary folder with a descriptive, sanitized filename outdir <- tempdir() path <- econanalyzr::econ_csv_write_out(df, folder = outdir, overwrite = TRUE) #> Wrote CSV: #> /tmp/RtmpccYq7b/2025-06-01_2025-01-01-monthly-quits_rate-percent-monthly-sa-nation-us-line.csv  basename(path) #> [1] \"2025-06-01_2025-01-01-monthly-quits_rate-percent-monthly-sa-nation-us-line.csv\"  file.exists(path) #> [1] TRUE"},{"path":"http://justanesta.com/econanalyzr/index.html","id":"data-visualization-examples","dir":"","previous_headings":"","what":"Data Visualization Examples","title":"Helps You Analyze Economic Data","text":"Economic ggplot2 data visualization templates come!","code":""},{"path":"http://justanesta.com/econanalyzr/reference/annualize_change.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate annualized rate of change — annualize_change","title":"Calculate annualized rate of change — annualize_change","text":"Computes annualized rate change paired start end values given time interval, annualizing according specified unit.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/annualize_change.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate annualized rate of change — annualize_change","text":"","code":"annualize_change(   start_values,   end_values,   time_elapsed,   time_unit = c(\"daily\", \"weekly\", \"monthly\", \"quarterly\", \"annually\"),   year_length = 365.2425 )"},{"path":"http://justanesta.com/econanalyzr/reference/annualize_change.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate annualized rate of change — annualize_change","text":"start_values Numeric scalar vector positive start values. end_values Numeric scalar vector positive end values. start_values, end_values, time_elapsed scalar, recycled common length; otherwise, lengths must compatible. time_elapsed Numeric scalar vector elapsed time time_unit start end. scalar, recycled. time_unit One \"daily\", \"weekly\", \"monthly\", \"quarterly\", \"annually\". year_length Days per year used time_unit \"daily\" (derive weeks/year time_unit \"weekly\"). Defaults 365.2425 (Gregorian average year).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/annualize_change.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate annualized rate of change — annualize_change","text":"numeric scalar vector annualized rates, length recycled inputs.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/annualize_change.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate annualized rate of change — annualize_change","text":"","code":"# Scalar (monthly): from 100 to 103 over 1 month -> annualized rate annualize_change(100, 103, time_elapsed = 1, time_unit = \"monthly\") #> [1] 0.4257609  # Vectorized (quarterly): scalar start recycled to match end/time vectors annualize_change(   start_values = 100,   end_values   = c(101, 98, 120),   time_elapsed = c(1, 2, 3),   time_unit    = \"quarterly\" ) #> [1]  0.04060401 -0.03960000  0.27519028  # Weekly with exact 52-week convention (52 * 7 = 364 days) annualize_change(   start_values = 100,   end_values   = 102,   time_elapsed = 4,   time_unit    = \"weekly\",   year_length  = 364 ) #> [1] 0.2936066"},{"path":"http://justanesta.com/econanalyzr/reference/cbsas.html","id":null,"dir":"Reference","previous_headings":"","what":"US Census Bureau CBSA Data — cbsas","title":"US Census Bureau CBSA Data — cbsas","text":"reference file names, codes, populations (via 2025 5-year ACS) US Census Bureau metropolitan micropolitan statistical areas together comprise core-based statistical areas (CBSAs).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/cbsas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US Census Bureau CBSA Data — cbsas","text":"","code":"cbsas"},{"path":[]},{"path":"http://justanesta.com/econanalyzr/reference/cbsas.html","id":"cbsas","dir":"Reference","previous_headings":"","what":"cbsas","title":"US Census Bureau CBSA Data — cbsas","text":"data frame 935 rows 7 columns: geo_id full Census Bureau GEOID geography. geo_entity_text plain text name geographic entity. pop_acs23_5yr estimated total population geography B01003 table 2023 5-year American Community Survey (ACS). sum_lev_code three-digit summary level code identify type Census geography. geo_entity_type_text plain text name geography level identified sum_lev_code column. geo_code characters \"US\" geo_id provide unique identifier within specified summary level. usps_state_abb two digit state abbreviation used USPS identify state. list-column vector multiple state abbreviations CBSA spans multiple states.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/cbsas.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"US Census Bureau CBSA Data — cbsas","text":"https://data.census.gov/","code":""},{"path":"http://justanesta.com/econanalyzr/reference/check_econanalyzr_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate econanalyzr tibble structure — check_econanalyzr_df","title":"Validate econanalyzr tibble structure — check_econanalyzr_df","text":"Enforces econanalyzr schema: First 9 required columns exact names expected low-level type & primary class: date (Date/double), date_period_text (character), value (numeric/double), data_element_text (character), data_measure_text (character), date_measure_text (character), data_transform_text (character), geo_entity_type_text (character), geo_entity_text (character). number optional columns may appear first 9. final column must viz_type_text type/class character.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/check_econanalyzr_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate econanalyzr tibble structure — check_econanalyzr_df","text":"","code":"check_econanalyzr_df(df, datetime_tz = \"UTC\")"},{"path":"http://justanesta.com/econanalyzr/reference/check_econanalyzr_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate econanalyzr tibble structure — check_econanalyzr_df","text":"df data frame tibble validate. datetime_tz String timezone used coercing POSIXct/POSIXlt Date. Defaults \"UTC\" deterministic behavior across environments.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/check_econanalyzr_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate econanalyzr tibble structure — check_econanalyzr_df","text":"validated tibble (possibly reordered /date/value coerced).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/check_econanalyzr_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate econanalyzr tibble structure — check_econanalyzr_df","text":"required columns viz_type_text present order, function emits warning reorders columns : required 9 (order) → optional(s) → viz_type_text. Special handling date: Accepts base Date subclasses. Subclasses coerced plain Date warning. Accepts zoo::yearmon/zoo::yearqtr (zoo installed) always coerces Date start period (first day month/quarter) warning. Accepts POSIXct/POSIXlt coerces Date (drop time) using datetime_tz. Special handling value: Must double; numeric double (e.g., integer numeric class), column coerced double warning. Non-numeric error. support yearmon/yearqtr, add zoo Suggests. yearmon/yearqtr column encountered zoo installed, classed error raised guidance.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/check_econanalyzr_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate econanalyzr tibble structure — check_econanalyzr_df","text":"","code":"# check_econanalyzr_df(valid_data)"},{"path":"http://justanesta.com/econanalyzr/reference/counties.html","id":null,"dir":"Reference","previous_headings":"","what":"US Census Bureau Counties Data — counties","title":"US Census Bureau Counties Data — counties","text":"reference file names, codes, populations (via 2025 5-year ACS) US Census Bureau counties county equivalents.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/counties.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US Census Bureau Counties Data — counties","text":"","code":"counties"},{"path":[]},{"path":"http://justanesta.com/econanalyzr/reference/counties.html","id":"counties","dir":"Reference","previous_headings":"","what":"counties","title":"US Census Bureau Counties Data — counties","text":"data frame 3,222 rows 10 columns: geo_id full Census Bureau GEOID geography. geo_entity_text plain text name geographic entity. pop_acs23_5yr estimated total population geography B01003 table 2023 5-year American Community Survey (ACS). sum_lev_code three-digit summary level code identify type Census geography. geo_entity_type_text plain text name geography level identified sum_lev_code column. state_fips first two digits full county fips_code identify state county . fips_code InterNational Committee Information Technology Standards (INCITS) formerly known Federal Information Processing Standards (FIPS) code ensure uniform identification geographic entities. fips_class_code Identifies type county county equivalent geography . func_stat_code Identifies functional status geography specified fips_code. ns_code National Standard (NS) code used US Geological Survey (USGS) geography.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/counties.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"US Census Bureau Counties Data — counties","text":"https://data.census.gov/","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_diffusion_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a diffusion index — create_diffusion_index","title":"Calculate a diffusion index — create_diffusion_index","text":"Computes diffusion index using one three common methodologies:","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_diffusion_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a diffusion index — create_diffusion_index","text":"","code":"create_diffusion_index(   pct_increased = NULL,   pct_decreased = NULL,   pct_unchanged = NULL,   pct_change = NULL,   idx_type = c(\"Federal Reserve\", \"IHS-PMI\", \"Conference Board\") )"},{"path":"http://justanesta.com/econanalyzr/reference/create_diffusion_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a diffusion index — create_diffusion_index","text":"pct_increased Numeric scalar vector [0, 1]: percent increased. pct_decreased Numeric scalar vector [0, 1]: percent decreased. pct_unchanged Numeric scalar vector [0, 1]: percent unchanged. pct_change Numeric scalar vector (finite real; may < 0 > 1): used \"Conference Board\". idx_type One \"Federal Reserve\" (default), \"IHS-PMI\", \"Conference Board\".","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_diffusion_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a diffusion index — create_diffusion_index","text":"\"Federal Reserve\" \"IHS-PMI\": numeric vector length recycled inputs. \"Conference Board\": single numeric scalar (encoded mean * 100).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_diffusion_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate a diffusion index — create_diffusion_index","text":"\"Federal Reserve\": \\((pct\\_increased - pct\\_decreased) * 100\\) \"IHS-PMI\": \\((pct\\_increased + 0.5 * pct\\_unchanged) * 100\\) \"Conference Board\": encode element pct_change 1 (), 0.5 (unchanged), 0 () using small threshold (default 0.05%), return \\(100 \\times \\mathrm{mean}(\\text{encoded}, na.rm=TRUE)\\).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Create indexed values from a numeric vector — create_index","title":"Create indexed values from a numeric vector — create_index","text":"Computes index column numeric vector relative base element: idx_type = 100: classic base-100 index (base value -> 100, others scaled). idx_type = 0  : percent change base (base value -> 0, others % difference).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create indexed values from a numeric vector — create_index","text":"","code":"create_index(num_vec, idx_pos = 1, idx_type = 100)"},{"path":"http://justanesta.com/econanalyzr/reference/create_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create indexed values from a numeric vector — create_index","text":"num_vec numeric vector length > 1. idx_pos base selector: either 1-based (integer-ish) position, —num_vec names—single character string matching one name. idx_type Numeric scalar, either 100 (base-100 index) 0 (percent change). Default 100.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create indexed values from a numeric vector — create_index","text":"numeric vector indexed values (length num_vec).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_index.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create indexed values from a numeric vector — create_index","text":"num_vec names, idx_pos may name base element (character) numeric (integer-ish) position. num_vec unnamed, idx_pos must numeric.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/create_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create indexed values from a numeric vector — create_index","text":"","code":"# Basic usage (base-100) create_index(c(50, 100, 150)) #> [1] 100 200 300  # Percent change from base (base -> 0%) create_index(c(50, 100, 150), idx_type = 0) #> [1]   0 100 200  # Using the second value as base (by position) create_index(c(90, 100, 120), idx_pos = 2) #> [1]  90 100 120  # Named vector: select base by name (only works because vector has names) x <- c(a = 80, b = 100, c = 120) create_index(x, idx_pos = \"b\")        # base-100 index with \"b\" as base #>   a   b   c  #>  80 100 120  create_index(x, idx_pos = \"b\", idx_type = 0)  # percent change from \"b\" #>   a   b   c  #> -20   0  20"},{"path":"http://justanesta.com/econanalyzr/reference/csas.html","id":null,"dir":"Reference","previous_headings":"","what":"US Census Bureau CSA Data — csas","title":"US Census Bureau CSA Data — csas","text":"reference file names, codes, populations (via 2025 5-year ACS) US Census Bureau combined statistical areas (CSAs).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/csas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US Census Bureau CSA Data — csas","text":"","code":"csas"},{"path":[]},{"path":"http://justanesta.com/econanalyzr/reference/csas.html","id":"csas","dir":"Reference","previous_headings":"","what":"csas","title":"US Census Bureau CSA Data — csas","text":"data frame 184 rows 7 columns: geo_id full Census Bureau GEOID geography. geo_entity_text plain text name geographic entity. pop_acs23_5yr estimated total population geography B01003 table 2023 5-year American Community Survey (ACS). sum_lev_code three-digit summary level code identify type Census geography. geo_entity_type_text plain text name geography level identified sum_lev_code column. geo_code characters \"US\" geo_id provide unique identifier within specified summary level. usps_state_abb two digit state abbreviation used USPS identify state. list-column vector multiple state abbreviations CBSA spans multiple states.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/csas.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"US Census Bureau CSA Data — csas","text":"https://data.census.gov/","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_calc_trail_avg.html","id":null,"dir":"Reference","previous_headings":"","what":"Append trailing-average rows in long form to econanalyzr data frame — econ_calc_trail_avg","title":"Append trailing-average rows in long form to econanalyzr data frame — econ_calc_trail_avg","text":"Computes trailing (right-aligned) moving average value appends rows original data (long form).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_calc_trail_avg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Append trailing-average rows in long form to econanalyzr data frame — econ_calc_trail_avg","text":"","code":"econ_calc_trail_avg(df, trail_amount)"},{"path":"http://justanesta.com/econanalyzr/reference/econ_calc_trail_avg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Append trailing-average rows in long form to econanalyzr data frame — econ_calc_trail_avg","text":"df econanalyzr-valid tibble/data frame. trail_amount Positive integer-like window size.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_calc_trail_avg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Append trailing-average rows in long form to econanalyzr data frame — econ_calc_trail_avg","text":"tibble containing original rows trailing-average rows.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_calc_trail_avg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Append trailing-average rows in long form to econanalyzr data frame — econ_calc_trail_avg","text":"Input must pass check_econanalyzr_df(). trail_amount must positive, integer-ish scalar (e.g., 3L, 6). df grouped tibble (via dplyr::group_by()), trailing average computed within group. ungrouped, computed entire table. Derived rows data_transform_text appended \"; Trail {n}\". Windows right-aligned .complete = TRUE: first trail_amount - 1 rows per group NA.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_csv_write_out.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a validated econanalyzr tibble to CSV with a descriptive filename — econ_csv_write_out","title":"Write a validated econanalyzr tibble to CSV with a descriptive filename — econ_csv_write_out","text":"See details prior message; unchanged contract.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_csv_write_out.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a validated econanalyzr tibble to CSV with a descriptive filename — econ_csv_write_out","text":"","code":"econ_csv_write_out(df, folder, overwrite = FALSE, quiet = FALSE)"},{"path":"http://justanesta.com/econanalyzr/reference/econ_csv_write_out.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a validated econanalyzr tibble to CSV with a descriptive filename — econ_csv_write_out","text":"df data frame/tibble satisfy check_econanalyzr_df(). folder Output directory. overwrite FALSE file exists, abort (default FALSE). quiet FALSE, emit info message (default FALSE).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_csv_write_out.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write a validated econanalyzr tibble to CSV with a descriptive filename — econ_csv_write_out","text":"Invisibly, file path written.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_filter_dates.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter rows in an econanalyzr data frame by a closed date interval — econ_filter_dates","title":"Filter rows in an econanalyzr data frame by a closed date interval — econ_filter_dates","text":"Filters econanalyzr-valid data frame closed date interval [start_date, end_date]. start_date supplied, can specify period (period_type + period_amount) function compute start_date = end_date - period (end_date defaulting latest non-NA date df).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_filter_dates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter rows in an econanalyzr data frame by a closed date interval — econ_filter_dates","text":"","code":"econ_filter_dates(   df,   start_date = NULL,   end_date = NULL,   period_type = c(\"days\", \"weeks\", \"months\", \"quarters\", \"years\"),   period_amount = NULL,   datetime_tz = \"UTC\",   quiet = FALSE )"},{"path":"http://justanesta.com/econanalyzr/reference/econ_filter_dates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter rows in an econanalyzr data frame by a closed date interval — econ_filter_dates","text":"df data frame validated check_econanalyzr_df(). start_date Optional Date POSIXt. NULL, must provide period_type period_amount derive . end_date Optional Date POSIXt. NULL, defaults latest non-NA date df. period_type Optional character scalar: one \"days\", \"weeks\", \"months\", \"quarters\", \"years\". Used start_date NULL. period_amount Optional positive integer-like scalar (e.g., 6 \"last 6 months\"). Used start_date NULL. datetime_tz Timezone coercing POSIXt inputs Date. Default \"UTC\". quiet FALSE (default), emit short message describing filter.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_filter_dates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter rows in an econanalyzr data frame by a closed date interval — econ_filter_dates","text":"filtered data frame, arranged descending date.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_filter_dates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter rows in an econanalyzr data frame by a closed date interval — econ_filter_dates","text":"interval inclusive: date >= start_date date <= end_date.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_filter_dates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter rows in an econanalyzr data frame by a closed date interval — econ_filter_dates","text":"","code":"# Last 6 months ending at the table’s latest date # econ_filter_dates(df, period_type = \"months\", period_amount = 6)  # Between two explicit dates # econ_filter_dates( #   df, #   start_date = as.Date(\"2024-01-01\"), #   end_date   = as.Date(\"2024-12-01\") # )"},{"path":"http://justanesta.com/econanalyzr/reference/econ_value_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a function to an econanalyzr data frame's numeric column after date filtering — econ_value_summary","title":"Apply a function to an econanalyzr data frame's numeric column after date filtering — econ_value_summary","text":"Filters econanalyzr-valid data frame either set membership dates (dates) closed range (date_range), pulls numeric column, applies user-supplied function .fun vector.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_value_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a function to an econanalyzr data frame's numeric column after date filtering — econ_value_summary","text":"","code":"econ_value_summary(   df,   dates = NULL,   date_range = NULL,   val_col = \"value\",   filter_type = c(\"inclusive\", \"exclusive\"),   .fun = mean,   na_rm = TRUE,   dates_tz = \"UTC\",   empty_ok = FALSE,   ... )"},{"path":"http://justanesta.com/econanalyzr/reference/econ_value_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a function to an econanalyzr data frame's numeric column after date filtering — econ_value_summary","text":"df data frame validated check_econanalyzr_df(). dates Optional Date (POSIXt) scalar/vector; rows date %% dates included/excluded per filter_type. POSIXt coerced Date using dates_tz. date_range Optional length-2 Date/POSIXt giving closed range [min(date_range), max(date_range)]. Ignored dates provided. val_col Column operate (must numeric): tidy-select name. Defaults column name value standard econanalyzr data frames. filter_type \"inclusive\" (keep matches) \"exclusive\" (drop matches). .fun function (function name) applied pulled vector, e.g. mean, median, function(x) stats::quantile(x, c(.25,.5,.75)). na_rm Logical; TRUE (default) remove NAs calling .fun. dates_tz Timezone coercing POSIXt (dates range) Date. Default \"UTC\". empty_ok FALSE (default) filter returns 0 rows, return NA_real_ warning. TRUE, pass length-0 vector .fun (may error). ... Extra arguments forwarded .fun.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_value_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a function to an econanalyzr data frame's numeric column after date filtering — econ_value_summary","text":"Whatever .fun returns (often scalar; may vector).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_value_summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply a function to an econanalyzr data frame's numeric column after date filtering — econ_value_summary","text":"Rules: dates date_range NULL, whole data used. supplied, classed error raised. filter yields 0 rows empty_ok = FALSE, returns NA_real_ warns. na_rm = TRUE, NAs removed calling .fun.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econ_value_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a function to an econanalyzr data frame's numeric column after date filtering — econ_value_summary","text":"","code":"# Mean of 'value' for a set of dates # econ_value_summary( #   df, dates = as.Date(c(\"2025-01-01\",\"2025-02-01\")), .fun = mean # )  # Median over a date range (exclusive: drop rows in range) # econ_value_summary( #   df, #   date_range = as.Date(c(\"2025-01-01\",\"2025-03-31\")), #   filter_type = \"exclusive\", #   .fun = median # )  # Vector result (quantiles) # econ_value_summary( #   df, #   dates = unique(df$date), #   .fun  = function(x) stats::quantile(x, c(.25,.5,.75)) # )"},{"path":"http://justanesta.com/econanalyzr/reference/econanalyzr-viz-helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute pixel and inch dimensions for visualization devices — econ_viz_dims","title":"Compute pixel and inch dimensions for visualization devices — econ_viz_dims","text":"Converts user-supplied width, height, units, dpi : integer pixel sizes (raster devices, e.g., PNG/JPEG/TIFF), floating-point inch sizes (vector devices, e.g., PDF/SVG). Opens base graphics device (png/jpeg/tiff/bmp/pdf/svg), prints ggplot, closes device. Raster devices use pixels + res; vector devices use inches. Uses ragg::agg_png(), ragg::agg_jpeg(), ragg::agg_tiff() high-quality raster output. Requires ragg Suggests. helper checks availability rlang::is_installed() never attaches ragg. Uses svglite::svglite() clean SVG output. Requires svglite Suggests. Checks availability rlang::is_installed() never attaches svglite. exactly one unique non-NA date, return YYYY-MM-DD. multiple, return maxDate_minDate (formatted YYYY-MM-DD). Errors non-NA dates date_vec Date/POSIXt. Produces conservative, filesystem-friendly slug: Lowercases string. Replaces whitespace (one ) underscores. Replaces character [-z0-9._-] underscores. Collapses multiple underscores single underscore. Trims leading/trailing underscores dots.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econanalyzr-viz-helpers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute pixel and inch dimensions for visualization devices — econ_viz_dims","text":"","code":"econ_viz_dims(width, height, units, dpi)  econ_viz_save_grdevices(plt, outpath, ext, dims, bg, dpi)  econ_viz_save_ragg(plt, outpath, ext, dims, bg, dpi)  econ_viz_save_svglite(plt, outpath, ext, dims)  make_file_name_date(date_vec)  make_metadata_vec(df_text, na_token = \"na\", warn_all_na = TRUE)  sanitize_filename(x)"},{"path":"http://justanesta.com/econanalyzr/reference/econanalyzr-viz-helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute pixel and inch dimensions for visualization devices — econ_viz_dims","text":"width, height Numeric scalars: requested size. units Character scalar: one \"px\", \"\", \"cm\", \"mm\". dpi Resolution (passed res). plt ggplot object print. outpath File path (including extension) write . ext Lowercased extension; must \"svg\". dims List econ_viz_dims(): width_in, height_in (inches). bg Background color (e.g., \"white\", \"transparent\"). date_vec Date vector (POSIXt allowed; coerced Date). df_text Data frame *_text columns. na_token Token use column NA. warn_all_na TRUE, warn column NA. x character vector (coerced via .character()).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econanalyzr-viz-helpers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute pixel and inch dimensions for visualization devices — econ_viz_dims","text":"list : width_in, height_in (numeric, inches) width_px, height_px (integer, pixels) character stem like \"2025-05-01\" \"2025-05-01_2021-05-01\". Character vector tokens column order. character vector sanitized filename stems, length x.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/econanalyzr-viz-helpers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute pixel and inch dimensions for visualization devices — econ_viz_dims","text":"used various econanalyzr visualization savers normalize sizing regardless graphics backend chosen. add extension; can append e.g. \".csv\" afterward. NA inputs returned NA.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/get_bls_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch a TSV from the BLS flat file database over HTTP with an email User-Agent and parse it — get_bls_data","title":"Fetch a TSV from the BLS flat file database over HTTP with an email User-Agent and parse it — get_bls_data","text":"Validates bls_url email string scalars, verifies email format, sends GET request using httr2 email User-Agent header request timeout, successful response Content-Type: text/plain text/tab-separated-values non-empty body, parses payload TSV via readr returns tibble.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/get_bls_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch a TSV from the BLS flat file database over HTTP with an email User-Agent and parse it — get_bls_data","text":"","code":"get_bls_data(bls_url, email)"},{"path":"http://justanesta.com/econanalyzr/reference/get_bls_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch a TSV from the BLS flat file database over HTTP with an email User-Agent and parse it — get_bls_data","text":"bls_url string scalar BLS URL (e.g., \"https://download.bls.gov/pub/time.series/jt/jt.data.1.AllItems\"). email string scalar email address include User-Agent header.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/get_bls_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch a TSV from the BLS flat file database over HTTP with an email User-Agent and parse it — get_bls_data","text":"tibble parsed TSV response body.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/get_bls_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fetch a TSV from the BLS flat file database over HTTP with an email User-Agent and parse it — get_bls_data","text":"Email validation uses practical regex rather full RFC 5322. HTTP errors (non-2xx) raise error status, reason, URL, response headers, short body snippet (best-effort). response successful text/plain text/tab-separated-values, body empty, error raised (headers included).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/get_bls_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fetch a TSV from the BLS flat file database over HTTP with an email User-Agent and parse it — get_bls_data","text":"","code":"if (FALSE) { # \\dontrun{ df <- get_bls_data(   bls_url = \"https://download.bls.gov/pub/time.series/jt/jt.data.1.AllItems\",   email   = \"you@example.com\" ) } # }"},{"path":"http://justanesta.com/econanalyzr/reference/naics_codes.html","id":null,"dir":"Reference","previous_headings":"","what":"North American Industry Classification System Data — naics_codes","title":"North American Industry Classification System Data — naics_codes","text":"reference file industry sector data NAICS code 2002 2022.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/naics_codes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"North American Industry Classification System Data — naics_codes","text":"","code":"naics_codes"},{"path":[]},{"path":"http://justanesta.com/econanalyzr/reference/naics_codes.html","id":"naics-codes","dir":"Reference","previous_headings":"","what":"naics_codes","title":"North American Industry Classification System Data — naics_codes","text":"data frame 11,186 rows 15 columns: year Year NAICS version. One 2022, 2017, 2012, 2007, 2002. code full NAICS code. code_title short description NAICS code. code_type type NAICS code. One Sector, Subsector, Industry Group, NAICS Industry, National Industry. Corresponds codes character lengths 2, 3, 4, 5, 6, respectively. code_desc longer description types businesses industries included NAICS code. code_cross_ref Additional descriptive information types businesses industries included NAICS code. change_desc Supplementary information code title industries included code changed since previous version NAICS. trilateral_agreement code included trilateral agreement Canada, U.S. Mexico included country's industry classification. code_sector two-digit sector code. ces_supersector_code supersector code NAICS industry used BLS Current Employment Statistics (CES). qcew_supersector_code supersector code NAICS industry used BLS Quarterly Census Employment Wages (QCEW). ces_domain_code domain (goods-producing vs. service-producing) code used BLS Current Employment Statistics (CES). qcew_domain_code domain (goods-producing vs. service-producing) code used BLS Quarterly Census Employment Wages (QCEW). supersector_title short description supersector NAICS code. domain_title One Goods-Producing vs. Service-Producing","code":""},{"path":"http://justanesta.com/econanalyzr/reference/naics_codes.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"North American Industry Classification System Data — naics_codes","text":"https://www.census.gov/naics/?48967","code":""},{"path":"http://justanesta.com/econanalyzr/reference/percent_change.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate percent change between two values — percent_change","title":"Calculate percent change between two values — percent_change","text":"Computes percent change start_value end_value: $$(end - start) / start$$","code":""},{"path":"http://justanesta.com/econanalyzr/reference/percent_change.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate percent change between two values — percent_change","text":"","code":"percent_change(start_value, end_value)"},{"path":"http://justanesta.com/econanalyzr/reference/percent_change.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate percent change between two values — percent_change","text":"start_value Numeric scalar vector starting values. end_value Numeric scalar vector ending values.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/percent_change.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate percent change between two values — percent_change","text":"numeric scalar vector percent changes (length recycled inputs).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/percent_change.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate percent change between two values — percent_change","text":"Vectorized tidyverse workflows (e.g., dplyr::mutate()).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/percent_change.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate percent change between two values — percent_change","text":"","code":"percent_change(100, 120)                      # 0.20 (20% increase) #> [1] 0.2 percent_change(c(100, 80), c(110, 72))        # c(0.10, -0.10) #> [1]  0.1 -0.1 percent_change(c(100, NA), c(110, 120))       # c(0.10, NA) #> Warning: NA values detected; returning NA for those positions. #> [1] 0.1  NA percent_change(0, 5)                          # NA with a warning (division by zero) #> Warning: Division by zero in `start_value`; returning NA for those positions. #> [1] NA"},{"path":"http://justanesta.com/econanalyzr/reference/regions_and_divisions.html","id":null,"dir":"Reference","previous_headings":"","what":"US Census Bureau Regions and Divisions Data — regions_and_divisions","title":"US Census Bureau Regions and Divisions Data — regions_and_divisions","text":"reference file names, codes, populations (via 2025 5-year ACS) US Census Bureau regions divisions.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/regions_and_divisions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US Census Bureau Regions and Divisions Data — regions_and_divisions","text":"","code":"regions_and_divisions"},{"path":[]},{"path":"http://justanesta.com/econanalyzr/reference/regions_and_divisions.html","id":"regions-and-divisions","dir":"Reference","previous_headings":"","what":"regions_and_divisions","title":"US Census Bureau Regions and Divisions Data — regions_and_divisions","text":"data frame 13 rows 6 columns: geo_id full Census Bureau GEOID geography geo_entity_text plain text name geographic entity. pop_acs23_5yr estimated total population geography B01003 table 2023 5-year American Community Survey (ACS). sum_lev_code three-digit summary level code identify type Census geography. geo_entity_type_text plain text name geography level identified sum_lev_code column. geo_code characters \"US\" geo_id provide unique identifier within specified summary level.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/regions_and_divisions.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"US Census Bureau Regions and Divisions Data — regions_and_divisions","text":"https://data.census.gov/","code":""},{"path":"http://justanesta.com/econanalyzr/reference/save_econanalyzr_chart.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a ggplot chart with an econanalyzr-style filename — save_econanalyzr_chart","title":"Save a ggplot chart with an econanalyzr-style filename — save_econanalyzr_chart","text":"Builds descriptive filename plot's data (supplied data frame): <date_or_range>-<meta1>-<meta2>-...-<metaK>.<ext>.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/save_econanalyzr_chart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a ggplot chart with an econanalyzr-style filename — save_econanalyzr_chart","text":"","code":"save_econanalyzr_chart(   plt,   folder,   data = NULL,   engine = c(\"ggsave\", \"grDevices\", \"ragg\", \"svglite\"),   device = \"png\",   format = \"png\",   width = 3600,   height = 2010,   units = \"px\",   dpi = 320,   scale = 1,   bg = \"white\",   overwrite = FALSE,   quiet = FALSE,   name_stem = NULL,   ... )"},{"path":"http://justanesta.com/econanalyzr/reference/save_econanalyzr_chart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a ggplot chart with an econanalyzr-style filename — save_econanalyzr_chart","text":"plt ggplot object. folder Output directory path. Created exist. data Optional data frame filename construction. NULL, uses plt$data. Must satisfy check_econanalyzr_df() classed error raised. engine Saving backend: one \"ggsave\" (default), \"grDevices\", \"ragg\", \"svglite\". device engine = \"ggsave\", device passed ggplot2::ggsave() (e.g., \"png\", \"pdf\", \"svg\", \"jpeg\", \"tiff\", device function). Ignored otherwise. format Output format/extension non-ggsave engines. One \"png\", \"pdf\", \"svg\", \"jpeg\", \"jpg\", \"tiff\", \"bmp\". Default \"png\". width, height Plot size (defaults target crisp social card): width = 3600, height = 2010. units Units width/height: \"px\" (default), \"\", \"cm\", \"mm\". dpi Resolution dots per inch (used raster devices converting inches). scale Scaling factor (multiplies width/height) passed ggsave() . bg Background: \"white\" (default), \"transparent\", etc. Passed raster devices / ggsave(). overwrite FALSE (default) target file exists, abort classed error. quiet FALSE (default) emit informational message success. name_stem Optional override filename stem (extension). sanitized. NULL, stem built data. ... Additional arguments forwarded ggplot2::ggsave() engine = \"ggsave\".","code":""},{"path":"http://justanesta.com/econanalyzr/reference/save_econanalyzr_chart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a ggplot chart with an econanalyzr-style filename — save_econanalyzr_chart","text":"(Invisibly) full file path written.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/save_econanalyzr_chart.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save a ggplot chart with an econanalyzr-style filename — save_econanalyzr_chart","text":"Filename construction reuses package helpers: make_file_name_date() date stem (single YYYY-MM-DD max_min range), make_metadata_vec() tokens derived *_text columns order, sanitize_filename() make safe, lowercase slug. Saving backends: engine = \"ggsave\" (default): calls ggplot2::ggsave(), honoring device, width, height, units, dpi, scale, bg, extra ... ggsave() supports. engine = \"grDevices\": opens base devices (png/jpeg/tiff/bmp/pdf/svg) via econ_viz_save_grdevices(). engine = \"ragg\": high-quality raster (png/jpeg/tiff) via econ_viz_save_ragg() (Suggests: ragg). engine = \"svglite\": vector SVG via econ_viz_save_svglite() (Suggests: svglite).","code":""},{"path":"http://justanesta.com/econanalyzr/reference/states.html","id":null,"dir":"Reference","previous_headings":"","what":"US Census Bureau States Data — states","title":"US Census Bureau States Data — states","text":"reference file names, codes, populations (via 2025 5-year ACS) US Census Bureau States.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/states.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US Census Bureau States Data — states","text":"","code":"states"},{"path":[]},{"path":"http://justanesta.com/econanalyzr/reference/states.html","id":"states","dir":"Reference","previous_headings":"","what":"states","title":"US Census Bureau States Data — states","text":"data frame 52 rows 9 columns: geo_id full Census Bureau GEOID geography. geo_entity_text plain text name geographic entity. pop_acs23_5yr estimated total population geography B01003 table 2023 5-year American Community Survey (ACS). sum_lev_code three-digit summary level code identify type Census geography. geo_entity_type_text plain text name geography level identified sum_lev_code column. usps_state_abb two digit state abbreviation used USPS identify state. region_name plain text name Census Bureau region state . information regions can found regions_and_divisions data set. division_name plain text name Census Bureau division state . information divisions can found regions_and_divisions data set. fips_code InterNational Committee Information Technology Standards (INCITS) formerly known Federal Information Processing Standards (FIPS) code ensure uniform identification geographic entities.","code":""},{"path":"http://justanesta.com/econanalyzr/reference/states.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"US Census Bureau States Data — states","text":"https://data.census.gov/","code":""},{"path":"http://justanesta.com/econanalyzr/news/index.html","id":"econanalyzr-100","dir":"Changelog","previous_headings":"","what":"econanalyzr 1.0.0","title":"econanalyzr 1.0.0","text":"Working adding included data sets additional common economic codes US Census Bureau.","code":""},{"path":[]},{"path":"http://justanesta.com/econanalyzr/news/index.html","id":"major-changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Major changes","title":"econanalyzr 1.0.0","text":"Added base analysis functions including percent_change(), annualize_change(), create_index(), create_diffusion_index(). Added data retrieval function get data BLS flat file data bases prompt users supply necessary valid email user-agent HTTPS header. Added functions work econanalyzr tibbles. include econ_value_summary(), econ_calc_trail_avg(), econ_filter_dates(), econ_csv_write_out().","code":""},{"path":"http://justanesta.com/econanalyzr/news/index.html","id":"minor-changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Minor changes","title":"econanalyzr 1.0.0","text":"Added helper data sets naics_codes reference file 2002-2022 NAICS codes. well regions_and_divisions, states, counties, cbsas, csas files additional metadata various common US Census Bureau regions","code":""}]
